## DeepCTR

1. CTR Prediction with Deep Learning

    CTR 예측에 딥러닝이 필요한 이유는 뭘까? 현실 세계의 CTR 데이터를 기존의 선형 모델로 예측하는데 한계가 있기 때문이다. 1. Highly sparse하고 Super high-dimensional한 feature를 가진 데이터가 대부분이며 2. highly non-linear한 연관관계가 feature 사이에서 나타나기 때문에 이러한 데이터에 효과적인 딥러닝 기법들이 CTR 예측 문제에 적용되기 시작했다

2. Wide & Deep

    선형적인 모델(Wide)와 비선형적인 모델(Deep)을 결합하여 기존 모델들의 장점들을 모두 취하고자 한 논문이다

    추천시스템에서는 해결해야할 두 가지의 과제가 존재한다 첫번째는 **Memorization**으로 빈번히 등장하는 feature 관계를 데이터로부터 학습하는 것이고, 두번째는 **Generalization**는 드물게 발생하거나 발생한 적 없는 특성 조합을 기존 관계로부터 발견하는 것이다

    Logistic Regression(LR)과 같은 선형 모델은 단순하고 확장 및 해석에 용이하나 학습 데이터에 없는 feature 조합에 취약하다(상대적으로 Memorization 능력은 뛰어나나 Generalization 능력은 떨어진다) 반대로 FM, DNN과 같은 임베딩 기반 모델은 일반화가 가능하지만 sparse한 데이터로부터 저차원의 임베딩을 만들기 어렵다는 단점이 존재한다 (상대적으로 Generalization 능력은 뛰어나나 Memorization 능력은 떨어진다) 이러한 이유로 논문에서는 둘을 결합해 사용자의 검색 쿼리에 맞는 앱을 추천하는 모델을 제안하였다

    Wide Component로는 Generalized Linear Model이 존재한다 해당 모델은 feature 간 관계를 파악하기 위해 feature 간 Cross-Product Transformation을 진행하였다 모든 feature의 Cross-Product Transformation를 진행할 경우 기하급수적으로 weight가 증가하기 떄문에 주요 피쳐 두개에 대한 cross-product만을 사용하였다(논문에선 과거 유저가 설치한 App과 CTR 예측할 App 두 개의 feature만을 cross-product하여 order-2 interaction 학습) 그러나 여전히 Polynomial Logistic Regression과 같이 표현할 수 있는 한계가 분명하다

    Deep Component는 Feed-Forward Neural Network를 사용하였다 3개의 layer로 구성되었으며 ReLU 함수를 통해 비선형성을 더하였다 Input으로 연속형 변수는 그대로 사용하였고 카테고리형 변수는 feature embedding 후 사용하였다

3. DeepFM

    Wide & Deep 모델과 달리 두 요소(wide, deep)가 입력값을 공유하도록 한 end-to-end 방식의 모델이다

    추천 시스템에서는 implicit feature interaction을 학습하는 것이 중요하다 예를 들어 식사 시간에 배달앱 다운로드 수가 증가하는 order-2 interaction이나 10대 남성이 슈팅/RPG 게임을 선호하는 order-3 interaction과 같은 interaction을 잘 발현해야한다

    하지만 기존 모델들은 low나 high-order interaction 중 어느 한 쪽에만 강하기 때문에 Wide & Deep 논문에서 문제를 해결하려는 시도가 있었으나 wide component에 feature engineering(Cross-product Transformation)이 필요하다는 단점이 존재한다)이에 반해 DeepFM 모델은 FM을 wide component로 사용해 입력값을 공유하도록 하였다

    FM Component는 기존 FM 모델과 동일한 구조로 sparse한 feature들이 embedding을 거친 후 inner product하는 과정을 통해 order-2 feature interaction을 효과적으로 잡았다

    Deep Component는 모든 feature를 동일한 k 차원의 임베딩으로 치환한다 여기서 임베딩에 사용되는 가중치는 FM Component에서 사용되는 가중치(V_ij)와 동일하다 즉 embedding layer는 FM Component와 Deep Component 따로 학습하지 않고 한꺼번에 학습된다 embedding layer를 거쳐 나온 값들은 concatenate 되어 hidden-layer의 input으로 들어간다
