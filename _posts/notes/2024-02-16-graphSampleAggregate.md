# 1. Introduction

<aside>
ğŸ’¡ The basic idea behind node embedding approaches is to use dimensionality reduction techniques to distill the high-dimensional information about a nodeâ€™s graph neighborhood into a dense vector embedding However, previous works have focused on embedding nodes from a single fixed graph, and many real-world applications require embeddings to be quickly generated for unseen nodes, or entirely new (sub)graphs.

</aside>

ë…¸ë“œ ì„ë² ë”©ì„ í†µí•´ ê·¸ë˜í”„ ì´ì›ƒ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” ê³ ì°¨ì›ì  ë°ì´í„°ì— ëŒ€í•œ ì°¨ì› ì¶•ì†Œë¥¼ ì´ë¤„ dense vector embeddingì„ ë§Œë“¤ê³ ì í•œë‹¤. ê·¸ëŸ°ë°, ìƒˆë¡œìš´ ë…¸ë“œì— ëŒ€í•´ ëŒ€ì‘í•˜ì§€ ëª»í•œë‹¤ëŠ” ë¬¸ì œê°€ ì¡´ì¬í•˜ì—¬ ë¹„ìŠ·í•œ í˜•íƒœì˜ ê·¸ë˜í”„ ì „ë°˜ì— ê±¸ì³ ë…¸ë“œ ì„ë² ë”©ì„ ì§„í–‰í•  ìˆ˜ ìˆëŠ” Inductiveí•œ approachê°€ í•„ìš”í•˜ë‹¤. (generalization)

Inductive node embeddingì€ transductiveì™€ëŠ” ë‹¬ë¦¬ ìƒˆë¡œ ê´€ì°°ëœ subgraphë“¤ì„ ì´ë¯¸ ìµœì í™”ë¥¼ ë§ˆì¹œ ì•Œê³ ë¦¬ì¦˜ì— ë§ê²Œ ì •ë ¬í•´ì•¼í•œë‹¤. ë˜,  nodeì˜ ì´ì›ƒë“¤ ê°ê°ì´ ê°€ì§€ëŠ” ì§€ì—­ì ì¸ ì—­í•  ë¿ë§Œ ì•„ë‹ˆë¼ ì „ì—­ì ì¸ ìœ„ì¹˜ì—ì„œ êµ¬ì¡°ì ì¸ íŠ¹ì„±ì„ ê³ ë ¤í•  ìˆ˜ ìˆì–´ì•¼í•œë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” ê¸°ì¡´ì— single/fixed graphë¥¼ í™œìš©í•˜ì—¬ transductiveí•œ GCNì— í•™ìŠµ ê°€ëŠ¥í•œ agg funcë¥¼ ë„£ìŒìœ¼ë¡œì¨ inductiveí•˜ê²Œ ë³€í˜•ì‹œí‚¤ëŠ” ê²ƒì´ ëª©í‘œì´ë‹¤.

Matrix Factorization ê¸°ë°˜ì˜ embedding approachë“¤ê³¼ëŠ” ë‹¬ë¦¬ ìƒˆë¡œìš´ nodeì— ëŒ€ì‘ ê°€ëŠ¥í•œ embedding functionì„ í•™ìŠµí•˜ê¸° ìœ„í•˜ì—¬ text attributes, node profile information, node degrees ì™€ ê°™ì€ node featureë“¤ì„ í™œìš©í•œë‹¤. ì € ì¹œêµ¬ê°€ ë‚´ ê·¼ì²˜ì— ìˆëŠ”ê°€ ì•„ë‹Œê°€ (topological structure) ë¿ë§Œ ì•„ë‹ˆë¼, ì € ì¹œêµ¬ê°€ ê°€ì§„ feature ì •ë³´ê¹Œì§€ ì–»ì–´ì™€ì„œ ë‚´ ì£¼ë³€ ì¹œêµ¬ë“¤ì˜ feature distributionê¹Œì§€ í•™ìŠµ í•  ìˆ˜ ìˆê²Œ ëœë‹¤.

GraphSAGE(SAmple and aggreGatE)ëŠ” Node ê°ê°ì´ ê°€ì§€ëŠ” embedding vectorë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì•„ë‹Œ, nodeì˜ local neighborhoodë¡œë¶€í„° feature ì •ë³´ë¥¼ aggreateí•˜ëŠ” **aggregator functionë“¤ì˜ ì§‘í•©ì„ í•™ìŠµ**í•˜ì˜€ë‹¤. **ê° aggregator functionì€ ê°ì ë‹¤ë¥¸ ê¸¸ì´ì˜ hopìœ¼ë¡œë¶€í„° ì˜¤ëŠ” ì •ë³´ë¥¼ aggregate** í•œë‹¤. í•´ë‹¹ aggregator functionë“¤ì€ ìƒˆë¡œìš´ ë…¸ë“œë“¤ì„ embeddingí•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤.

# 2. Related work

Factorization-based embedding approaches (random walk, Spectral Clustering, PageRank, multi-dimensional scaling)

ê° ë…¸ë“œë³„ë¡œ Node Embeddingì„ ì§ì ‘ì ìœ¼ë¡œ ì§„í–‰í•˜ê¸°ì— ìƒˆë¡œìš´ nodeì— ëŒ€í•œ embeddingì„ êµ¬í•˜ê¸° ìœ„í•´ì„  ë¶€ê°€ì ì¸ í”„ë¡œì„¸ìŠ¤ í•„ìš”í•˜ë‹¤.

Supervised learning over graphs (recent neural network approaches)

Node-Embedding Approachê°€ ì•„ë‹Œ graph-structure ì „ì²´ì— ëŒ€í•œ supervised learningì„ ì§„í–‰í•œë‹¤. ì¦‰, ì „ì²´ ê·¸ë˜í”„ë¥¼ ë¶„ë¥˜í•˜ë ¤ëŠ” ì‹œë„ë“¤ì´ì§€ë§Œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ê° ë…¸ë“œë³„ representationì„ êµ¬í•˜ëŠ” ê²ƒì´ ëª©í‘œì´ë‹¤.

Graph convolutional networks

Graph ë°ì´í„°ì— CNNì„ í™œìš©í•˜ê³ ì í•œ ì›€ì§ì„ì€ ìì£¼ ìˆì—ˆìœ¼ë‚˜ Large Graphì— ì í•©í•˜ì§€ ì•Šê±°ë‚˜, ì „ì²´ ê·¸ë˜í”„ì— ëŒ€í•œ ë¶„ë¥˜ ìˆ˜í–‰ì„ ëª©ì ìœ¼ë¡œ ë‘ê³  ë“±ì¥í•˜ì˜€ë‹¤. ê·¸ ì¤‘ GCNì€ graph Laplacianì„ í›ˆë ¨ ê³¼ì •ì— ì´ìš©í•˜ëŠ” transductive settingì„ ì‚¬ìš©í•˜ê³  ìˆì–´ GraphSAGEëŠ” inductive settingì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í™•ì¥í•˜ì˜€ë‹¤.

# 3. Proposed method: GraphSAGE

## 3.1 Embedding generation algorithm

ì£¼ë³€ ë…¸ë“œê°€ ê°€ì§€ëŠ” feature ì •ë³´ë¥¼ ì–´ë–»ê²Œ Aggregate í• ì§€ í•™ìŠµ

1. GraphSAGE ëª¨ë¸ì´ í•™ìŠµë˜ì–´ìˆë‹¤ê³  ê°€ì •í•  ë•Œ Embedding ìƒì„± ê³¼ì •ì— ëŒ€í•´ ì„¤ëª…
2. ì´í›„ì— SGD ê¸°ë°˜ìœ¼ë¡œ ì–´ë–»ê²Œ GraphSAGE  parameter í•™ìŠµë˜ëŠ”ì§€ ì„¤ëª…

GraphSAGE ëª¨ë¸ì´ í•™ìŠµë˜ì–´ìˆë‹¤ê³  ê°€ì •í•œë‹¤ë©´, 

Kê°œì˜ aggregator function (ì£¼ë³€ ë…¸ë“œë¡œë¶€í„° ì •ë³´ë¥¼ ì§‘ê³„)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5ff7e13f-04e3-4ace-95d7-b1d964b10c87/9e7420f9-4db1-4de8-a963-acf2c97ccf11/Untitled.png)

Kê°œì˜ Weight Matrix (ì„œë¡œ ë‹¤ë¥¸ hopê°„ ì •ë³´ë¥¼ ì „ë‹¬)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5ff7e13f-04e3-4ace-95d7-b1d964b10c87/eb7172c6-9aeb-4477-96d8-26e53e2d3e54/Untitled.png)

Embedding Generation Algorithm

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5ff7e13f-04e3-4ace-95d7-b1d964b10c87/fed02564-18ef-4798-83c0-ae6edeb14163/Untitled.png)

2: K-hop ë§Œí¼ ë°˜ë³µ

3: ëª¨ë“  nodeì— ëŒ€í•´ ì§„í–‰

4: ì£¼ë³€ ë…¸ë“œë“¤ì˜ embeddingì„ aggregate

5: 4 ê³¼ì •ì„ í†µí•´ ì–»ì€ embeddingê³¼ í˜„ ë…¸ë“œì˜ ì´ì „ embeddingì„ concatí•˜ì—¬ embeddingì„ êµ¬í•œë‹¤

Neighborhood definition

ìœ„ Algorithm ì† 4ë²ˆ ê³¼ì •ì—ì„œ ì£¼ë³€ ë…¸ë“œëŠ” ê° ë°°ì¹˜ ë³„ë¡œ ê³„ì‚°ëŸ‰ì„ ë™ì¼í•˜ê²Œ ê°€ì ¸ê°€ê¸° ìœ„í•´ samplingì„ í†µí•´ fixed-sizeë¡œ êµ¬í•´ì˜¨ë‹¤. (ì†ë„ ë¿ë§Œ ì•„ë‹ˆë¼ ì„±ëŠ¥ê¹Œì§€ ì¢‹ì•„ì§ì„ í™•ì¸í•¨)

## 3.2 Learning the parameters of GraphSAGE

Unsupervised settingì„ ìœ„í•´ output representationì— ëŒ€í•´ graph-based loss function ì ìš©

graph-based loss function

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5ff7e13f-04e3-4ace-95d7-b1d964b10c87/5ee2d52b-915f-4066-a4bf-d2e7df9123c6/Untitled.png)

ê°€ê¹Œìš´ ë…¸ë“œì¼ìˆ˜ë¡ ë¹„ìŠ·í•œ representation, ë¨¼ ë…¸ë“œì¼ìˆ˜ë¡ êµ¬ë¶„ë˜ëŠ” representationì„ ê°€ì§€ë„ë¡ í•™ìŠµ

vëŠ” uë¡œë¶€í„° ê³ ì •ëœ ê¸¸ì´ì˜ random-walkì— ì˜í•´ ë°œìƒí•œ ë…¸ë“œ

Pnì€ negative sampling distributionì´ê³ , QëŠ” negative sampleë“¤ì˜ ìˆ«ìì´ë‹¤.

**ì—¬ê¸°ì„œ ì¤‘ìš”í•œ ê²ƒì€ representation zu ê°€ embedding look-upì„ í†µí•´ ë½‘ì•„ì˜¨ ê° ë…¸ë“œ ë³„ ê³ ìœ  embedding vectorê°€ ì•„ë‹ˆë¼, ì£¼ë³€ ë…¸ë“œì˜ featureìœ¼ë¡œë¶€í„° ìƒì„±ëœ representationì´ë¼ëŠ” ê²ƒì´ë‹¤.**

## 3.3 Aggregator Architecture

ì¼ë°˜ì ì¸ N-Dì°¨ì›ì˜ ë°ì´í„°ë“¤ (text, image) ê³¼ëŠ” ë‹¤ë¥´ê²Œ nodeì˜ ì´ì›ƒë“¤ì€ ìˆœì„œì— ì˜í–¥ì„ ë°›ì•„ì„œëŠ” ì•ˆëœë‹¤. ì´ëŸ¬í•œ ì´ìœ ë¡œ aggregator functionì€ symmetric ( inputì˜ ìˆœì—´ì— ì˜í–¥ ë°›ì§€ ì•ŠìŒ ) í•´ì•¼í•œë‹¤. 

### 1. Mean Aggregator

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5ff7e13f-04e3-4ace-95d7-b1d964b10c87/01899ee3-f1c8-4e1f-977a-359a2984a439/Untitled.png)

Algorithm 1ì˜ 4,5ë²ˆ ê³¼ì •ì„ ìœ„ ìˆ˜ì‹ìœ¼ë¡œ ëŒ€ì²´í•œë‹¤ë©´, GCNì˜ inductiveí•œ propagation ruleì„ ìœ ë„í•´ë‚¼ ìˆ˜ ìˆë‹¤. (modified mean-based aggregator convolution, Localized Spectral Convolutionì„ linear approximationí•œ ê³¼ì •)

ë’¤ì— ì†Œê°œí•  aggregatorë“¤ê³¼ ë‹¤ë¥¸ ì´ aggregatorë§Œì˜ íŠ¹ì§•ì€ concat ê³¼ì •ì´ ì—†ë‹¤ëŠ” ì ì´ ìˆëŠ”ë°, concat ê³¼ì •ì€ skip connectionê³¼ ê°™ì€ ì—­í• ì„ í•˜ëŠ”ë°, (ì´ì „ ë…¸ë“œ ìƒíƒœë¥¼ ê·¸ëŒ€ë¡œ ë°˜ì˜í•œë‹¤ëŠ” ì ì´ ë¹„ìŠ·) í° ì„±ëŠ¥ì„ ì´ëŒì–´ì¤€ë‹¤.

### 2. LSTM Aggregator

LSTMì„ aggregatorë¡œ ì‚¬ìš©í•œë‹¤ë©´ í‘œí˜„ë ¥ì´ í’ë¶€í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆì§€ë§Œ, symmetricí•˜ì§€ ëª»í•˜ë‹¤ëŠ” ë¬¸ì œì ì´ ì¡´ì¬í•œë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë…¼ë¬¸ì—ì„œëŠ” ì£¼ë³€ ë…¸ë“œë“¤ì˜ ìˆœì„œë¥¼ ëœë¤í•˜ê²Œ ë¶€ì—¬í•˜ì—¬ í•™ìŠµì‹œí‚¨ë‹¤.

### 3. Pooling Aggregator

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5ff7e13f-04e3-4ace-95d7-b1d964b10c87/36d05f59-34d3-4951-b3f0-07fde93b1dd2/Untitled.png)

ë§ˆì§€ë§‰ìœ¼ë¡œ Pooling ê¸°ë²•ì€ symmetricí•˜ê³ , í•™ìŠµ ê°€ëŠ¥í•˜ë‹¤. ìœ„ ìˆ˜ì‹ì—ì„œëŠ” single layerë¡œ êµ¬ì„±ë˜ì—ˆì§€ë§Œ multi-layerë¡œë„ êµ¬ì„±í•  ìˆ˜ ìˆë‹¤. (Wpool: neighbor setì— ì¡´ì¬í•˜ëŠ” ë…¸ë“œì˜ featureë“¤ì„ í‘œí˜„í•˜ëŠ” ì—­í• )

max-pooling operatorëŠ” ê° ë…¸ë“œì˜ ì´ì›ƒ ë³„ë¡œ ê³„ì‚°ëœ representationë“¤ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì£¼ë³€ ë…¸ë“œë“¤ì˜ ì¤‘ìš”í•œ íŠ¹ì§•ì„ ì¶”ì¶œí•´ë‚¼ ìˆ˜ ìˆë‹¤.